# -*- coding: utf-8 -*-
"""
ã€æ•°æ®é›†ä¼˜åŒ–å™¨ã€‘V1.0
åŠŸèƒ½ï¼š
1. è‡ªåŠ¨é™é‡‡æ ·è¿‡å¤šçš„ GameParameter
2. ç”ŸæˆçœŸæ­£çš„ Event+Target å·¥ä½œæµæ ·æœ¬ï¼ˆContainer + Event ä¸€ä½“ï¼‰
3. å¹³è¡¡æ•°æ®é›†å„ç±»å‹å æ¯”

ä½¿ç”¨æ–¹æ³•ï¼š
    python dataset_optimizer.py combined_wwise_data_v1.jsonl -o optimized_dataset.jsonl
"""

import json
import random
import argparse
from collections import Counter
from typing import List, Dict

# =============================================================================
# ç›®æ ‡å æ¯”é…ç½®
# =============================================================================

# ç†æƒ³çš„æ•°æ®ç±»å‹å æ¯”
TARGET_RATIOS = {
    "RandomSequenceContainer": 0.20,  # 20%
    "SwitchContainer": 0.15,          # 15%
    "BlendContainer": 0.03,           # 3%
    "ActorMixer": 0.03,               # 3%
    "Event": 0.25,                    # 25% (å«å·¥ä½œæµ)
    "Attenuation": 0.08,              # 8%
    "GameParameter": 0.10,            # 10% â† ä»30%é™åˆ°10%
    "SwitchGroup": 0.08,              # 8%
    "StateGroup": 0.08,               # 8%
}

# å¯ç”Ÿæˆå·¥ä½œæµçš„å®¹å™¨ç±»å‹
WORKFLOW_CONTAINER_TYPES = [
    "RandomSequenceContainer",
    "SwitchContainer", 
    "BlendContainer",
]

# =============================================================================
# å·¥ä½œæµç”Ÿæˆå™¨
# =============================================================================

class WorkflowGenerator:
    """ç”Ÿæˆ Event+Target å®Œæ•´å·¥ä½œæµæ ·æœ¬"""
    
    # Instruction æ¨¡æ¿
    WORKFLOW_TEMPLATES = [
        "åˆ›å»º {name} çš„å®Œæ•´éŸ³æ•ˆç»“æ„ï¼Œå¹¶ç”Ÿæˆå¯¹åº”çš„æ’­æ”¾ Event",
        "å¸®æˆ‘æ­å»º {name}ï¼ŒåŒ…å«éŸ³æ•ˆå±‚çº§å’Œè§¦å‘äº‹ä»¶",
        "åš {name} çš„ SFX ç»“æ„å’Œæ’­æ”¾ Event",
        "åˆ›å»º {name} ç›¸å…³çš„éŸ³æ•ˆå’Œ Eventï¼Œè¦èƒ½åœ¨æ¸¸æˆä¸­æ’­æ”¾",
        "æ„å»º {name} çš„å®Œæ•´å·¥ä½œæµï¼šå…ˆå»ºç»“æ„ï¼Œå†å»ºäº‹ä»¶",
        "ç”Ÿæˆ {name} çš„éŸ³æ•ˆå±‚çº§ï¼Œå¹¶åˆ›å»º Play Event",
        "æ­å»º {name}ï¼Œéœ€è¦åŒ…å«å®¹å™¨ç»“æ„å’Œå¯¹åº”çš„è§¦å‘ Event",
        "åšä¸€å¥— {name} çš„å®Œæ•´éŸ³æ•ˆï¼ŒåŒ…æ‹¬å±‚çº§å’Œæ’­æ”¾äº‹ä»¶",
    ]
    
    # Event çˆ¶çº§é€‰é¡¹
    EVENT_PARENTS = ["Default Work Unit", "SFX", "Skills", "Combat", "Player", "Monster"]
    
    @classmethod
    def generate_workflow_sample(cls, container_sample: Dict) -> Dict:
        """
        ä» Container æ ·æœ¬ç”Ÿæˆå·¥ä½œæµæ ·æœ¬
        
        å°† Container çš„ DSL ä»£ç  + Event åˆ›å»ºåˆå¹¶ä¸ºä¸€ä¸ªå®Œæ•´å·¥ä½œæµ
        """
        root_name = container_sample.get("meta", {}).get("root_name", "Unknown")
        root_type = container_sample.get("meta", {}).get("root_type", "")
        original_output = container_sample.get("output", "")
        
        # ç”Ÿæˆ Event éƒ¨åˆ†
        event_parent = random.choice(cls.EVENT_PARENTS)
        event_name = f"Play_{root_name}"
        
        event_dsl = f'\nCREATE Event "{event_name}" UNDER "{event_parent}"\n'
        event_dsl += f'ADD_ACTION "{event_name}" PLAY "{root_name}"'
        
        # åˆå¹¶ DSL
        combined_output = original_output + "\n" + event_dsl
        
        # ç”Ÿæˆæ–°çš„ instruction
        instruction = random.choice(cls.WORKFLOW_TEMPLATES).format(name=root_name)
        
        # ç»Ÿè®¡å‘½ä»¤
        commands = {
            "CREATE": combined_output.count("CREATE"),
            "SET_PROP": combined_output.count("SET_PROP"),
            "LINK": combined_output.count("LINK"),
            "ASSIGN": combined_output.count("ASSIGN"),
            "ADD_ACTION": combined_output.count("ADD_ACTION"),
        }
        
        # æ„å»ºæ–°æ ·æœ¬
        workflow_sample = {
            "instruction": instruction,
            "input": "",
            "output": combined_output,
            "meta": {
                "source": "workflow_generated",
                "root_type": "Workflow",  # æ ‡è®°ä¸ºå·¥ä½œæµç±»å‹
                "root_name": root_name,
                "line_count": combined_output.count("\n") + 1,
                "depth": container_sample.get("meta", {}).get("depth", 1) + 1,
                "complexity": "medium",
                "commands": commands,
                "container_type": root_type,
                "event_name": event_name,
            }
        }
        
        return workflow_sample


# =============================================================================
# æ•°æ®é›†ä¼˜åŒ–å™¨
# =============================================================================

class DatasetOptimizer:
    """æ•°æ®é›†ä¼˜åŒ–å™¨"""
    
    def __init__(self, samples: List[Dict], seed: int = 42):
        self.samples = samples
        self.seed = seed
        random.seed(seed)
    
    def analyze(self):
        """åˆ†æå½“å‰æ•°æ®é›†"""
        type_counter = Counter()
        for s in self.samples:
            root_type = s.get("meta", {}).get("root_type", "Unknown")
            type_counter[root_type] += 1
        
        print("=" * 60)
        print("ğŸ“Š å½“å‰æ•°æ®é›†åˆ†å¸ƒ")
        print("=" * 60)
        
        total = len(self.samples)
        for t, count in type_counter.most_common():
            pct = count / total * 100
            print(f"   {t}: {count} ({pct:.1f}%)")
        
        return type_counter
    
    def downsample_type(self, type_name: str, target_ratio: float) -> List[Dict]:
        """
        é™é‡‡æ ·æŒ‡å®šç±»å‹åˆ°ç›®æ ‡å æ¯”
        """
        # åˆ†ç¦»ç›®æ ‡ç±»å‹å’Œå…¶ä»–ç±»å‹
        target_samples = []
        other_samples = []
        
        for s in self.samples:
            if s.get("meta", {}).get("root_type") == type_name:
                target_samples.append(s)
            else:
                other_samples.append(s)
        
        current_count = len(target_samples)
        other_count = len(other_samples)
        
        # è®¡ç®—ç›®æ ‡æ•°é‡
        # target_ratio = target_count / (target_count + other_count)
        # target_count = target_ratio * other_count / (1 - target_ratio)
        target_count = int(target_ratio * other_count / (1 - target_ratio))
        target_count = min(target_count, current_count)  # ä¸èƒ½è¶…è¿‡å½“å‰æ•°é‡
        
        print(f"\nğŸ”§ é™é‡‡æ · {type_name}:")
        print(f"   å½“å‰: {current_count}")
        print(f"   ç›®æ ‡: {target_count}")
        print(f"   åˆ é™¤: {current_count - target_count}")
        
        # éšæœºé‡‡æ ·
        if target_count < current_count:
            target_samples = random.sample(target_samples, target_count)
        
        return other_samples + target_samples
    
    def generate_workflows(self, ratio: float = 0.3) -> List[Dict]:
        """
        ä¸ºéƒ¨åˆ† Container æ ·æœ¬ç”Ÿæˆå·¥ä½œæµç‰ˆæœ¬
        
        Args:
            ratio: ç”Ÿæˆå·¥ä½œæµçš„æ¯”ä¾‹ï¼ˆé»˜è®¤ 30% çš„ Container ä¼šæœ‰å·¥ä½œæµç‰ˆæœ¬ï¼‰
        """
        workflow_samples = []
        container_count = 0
        
        for s in self.samples:
            root_type = s.get("meta", {}).get("root_type", "")
            
            if root_type not in WORKFLOW_CONTAINER_TYPES:
                continue
            
            container_count += 1
            
            # æŒ‰æ¯”ä¾‹ç”Ÿæˆ
            if random.random() > ratio:
                continue
            
            # æ£€æŸ¥åŸå§‹ output é•¿åº¦ï¼Œå¤ªé•¿çš„ä¸ç”Ÿæˆå·¥ä½œæµ
            original_lines = s.get("meta", {}).get("line_count", 0)
            if original_lines > 60:  # è¶…è¿‡60è¡Œçš„ä¸ç”Ÿæˆï¼Œé¿å…å¤ªé•¿
                continue
            
            workflow = WorkflowGenerator.generate_workflow_sample(s)
            workflow_samples.append(workflow)
        
        print(f"\nğŸ”§ ç”Ÿæˆ Event+Target å·¥ä½œæµ:")
        print(f"   å¯ç”¨ Container: {container_count}")
        print(f"   ç”Ÿæˆå·¥ä½œæµ: {len(workflow_samples)}")
        
        return workflow_samples
    
    def optimize(
        self,
        downsample_gameparam: bool = True,
        generate_workflows: bool = True,
        workflow_ratio: float = 0.3,
    ) -> List[Dict]:
        """
        æ‰§è¡Œå®Œæ•´ä¼˜åŒ–
        """
        print("\n" + "=" * 60)
        print("ğŸš€ å¼€å§‹æ•°æ®é›†ä¼˜åŒ–")
        print("=" * 60)
        
        optimized = self.samples.copy()
        
        # 1. é™é‡‡æ · GameParameter
        if downsample_gameparam:
            optimized = self.downsample_type("GameParameter", TARGET_RATIOS["GameParameter"])
            self.samples = optimized  # æ›´æ–°å¼•ç”¨
        
        # 2. ç”Ÿæˆå·¥ä½œæµæ ·æœ¬
        workflows = []
        if generate_workflows:
            workflows = self.generate_workflows(ratio=workflow_ratio)
        
        # 3. åˆå¹¶
        final = optimized + workflows
        
        # 4. æ‰“ä¹±
        random.shuffle(final)
        
        # 5. æœ€ç»ˆç»Ÿè®¡
        print("\n" + "=" * 60)
        print("ğŸ“Š ä¼˜åŒ–åæ•°æ®é›†åˆ†å¸ƒ")
        print("=" * 60)
        
        type_counter = Counter()
        for s in final:
            root_type = s.get("meta", {}).get("root_type", "Unknown")
            type_counter[root_type] += 1
        
        total = len(final)
        for t, count in type_counter.most_common():
            pct = count / total * 100
            # æ ‡è®°æ”¹å–„
            if t == "GameParameter":
                status = "âœ… å·²ä¼˜åŒ–" if pct < 15 else "âš ï¸"
            elif t == "Workflow":
                status = "âœ… æ–°å¢"
            else:
                status = ""
            print(f"   {t}: {count} ({pct:.1f}%) {status}")
        
        print(f"\n   æ€»è®¡: {total}")
        
        return final


# =============================================================================
# ä¸»å‡½æ•°
# =============================================================================

def load_jsonl(path: str) -> List[Dict]:
    """åŠ è½½ JSONL æ–‡ä»¶"""
    samples = []
    with open(path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                samples.append(json.loads(line))
    return samples


def save_jsonl(samples: List[Dict], path: str):
    """ä¿å­˜ JSONL æ–‡ä»¶"""
    with open(path, 'w', encoding='utf-8') as f:
        for s in samples:
            f.write(json.dumps(s, ensure_ascii=False) + '\n')


def main():
    parser = argparse.ArgumentParser(description="æ•°æ®é›†ä¼˜åŒ–å™¨")
    parser.add_argument("input", type=str, help="è¾“å…¥ JSONL æ–‡ä»¶")
    parser.add_argument("-o", "--output", type=str, help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--no-downsample", action="store_true", 
                        help="ä¸é™é‡‡æ · GameParameter")
    parser.add_argument("--no-workflow", action="store_true",
                        help="ä¸ç”Ÿæˆå·¥ä½œæµæ ·æœ¬")
    parser.add_argument("--workflow-ratio", type=float, default=0.3,
                        help="å·¥ä½œæµç”Ÿæˆæ¯”ä¾‹ (é»˜è®¤ 0.3)")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ® Wwise æ•°æ®é›†ä¼˜åŒ–å™¨ V1.0")
    print("=" * 60)
    
    # åŠ è½½
    print(f"\nğŸ“‚ åŠ è½½: {args.input}")
    samples = load_jsonl(args.input)
    print(f"   æ ·æœ¬æ•°: {len(samples)}")
    
    # åˆ†æ
    optimizer = DatasetOptimizer(samples, seed=args.seed)
    optimizer.analyze()
    
    # ä¼˜åŒ–
    optimized = optimizer.optimize(
        downsample_gameparam=not args.no_downsample,
        generate_workflows=not args.no_workflow,
        workflow_ratio=args.workflow_ratio,
    )
    
    # ä¿å­˜
    if args.output:
        output_path = args.output
    else:
        import os
        base, ext = os.path.splitext(args.input)
        output_path = f"{base}_optimized{ext}"
    
    save_jsonl(optimized, output_path)
    print(f"\nâœ… å·²ä¿å­˜: {output_path}")
    
    # è¾“å‡ºå·¥ä½œæµç¤ºä¾‹
    workflow_samples = [s for s in optimized if s.get("meta", {}).get("root_type") == "Workflow"]
    if workflow_samples:
        print("\n" + "=" * 60)
        print("ğŸ“ å·¥ä½œæµæ ·æœ¬ç¤ºä¾‹")
        print("=" * 60)
        example = workflow_samples[0]
        print(f"\nInstruction: {example['instruction']}")
        print(f"\nOutput (å‰30è¡Œ):")
        lines = example['output'].split('\n')[:30]
        for line in lines:
            print(f"  {line}")
        if len(example['output'].split('\n')) > 30:
            print("  ...")


if __name__ == "__main__":
    main()
